{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52921fb1-00b2-4713-ae32-e7a748d51852",
   "metadata": {},
   "source": [
    "# Re-post-processing\n",
    "---\n",
    "\n",
    "**Author**: Ryan Lane \\\n",
    "**Date**: 13 February 2023\n",
    "\n",
    "#### Overview\n",
    "Reapply post-processing corrections for FAST-EM but with subset of raw images filtered by artefact detection. Corrections are effectively just a background subtraction where background is estimated from mean (fields, axis=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6645269d-1789-4c38-ae47-300d00c647b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(folder, output_subdir):\n",
    "    restore_mean_level = 32768\n",
    "    os.chdir(folder)\n",
    "    correction_files = glob.glob('*.tiff')\n",
    "    logging.info(\"Calculate the gain correction of current directory *.tiff files. Results are places in '/corrected/..'.\")\n",
    "    try:\n",
    "        os.mkdir(output_subdir)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        first_done = False\n",
    "        nr_off_images = 0\n",
    "        logging.info('First pass (takes a minute): Calculate gain correction parameters and cell statistics from .tiff files in current folder...')\n",
    "    for f in correction_files:\n",
    "        if not first_done:\n",
    "            sum_of_files = ScanFieldImage.load(f)\n",
    "            first_done = True\n",
    "        else:\n",
    "            im = ScanFieldImage.load(f)\n",
    "            sum_of_files = np.add(sum_of_files, im)\n",
    "        nr_off_images = nr_off_images + 1\n",
    "    else:\n",
    "        sum_of_files = sum_of_files / nr_off_images\n",
    "        sum_of_files.save('corrected/sum_of_files.tiff')\n",
    "        gainreff = sum_of_files.slice()\n",
    "        gainlist = ScanFieldImage.gaindeviation(gainreff)\n",
    "        cf = open('corrected/gaincorrection.txt', 'w')\n",
    "        for g in gainlist:\n",
    "            cf.write(str(g) + '\\r\\n')\n",
    "        else:\n",
    "            cf.close()\n",
    "            logging.info('Second pass (takes some more time): Perform field fixed pattern correction...')\n",
    "            for index, f in enumerate(glob.glob('*.tiff')):\n",
    "                field = ScanFieldImage.load(f)\n",
    "                fieldimage = np.subtract(field, sum_of_files)\n",
    "                fieldimage = fieldimage + restore_mean_level\n",
    "                fieldimage.save('corrected/' + f, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e8beeb-e651-4f9b-a037-5ce233acd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get autocomplete to work\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e99147f-2371-4a6e-84fc-b27906ea3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import exposure\n",
    "from tifffile import TiffFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf22fe-a09f-4e0e-b15c-249c409e446f",
   "metadata": {},
   "source": [
    "### Gather image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03300a90-e6ad-4345-8fc2-3fffa39ecb46",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './acquisitions.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load acquisition filepath data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_fps \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./acquisitions.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_fps\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fastem/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fastem/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fastem/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/fastem/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fastem/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/fastem/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './acquisitions.txt'"
     ]
    }
   ],
   "source": [
    "# Load acquisition filepath data\n",
    "df_fps = pd.read_csv('./acquisitions.txt', delimiter='\\t').set_index('Z')\n",
    "df_fps.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebac5e-2873-4770-91be-b42143f57d5f",
   "metadata": {},
   "source": [
    "### Reprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4aab307-7525-4d13-9a2e-e516acd71086",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'outlier_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moutlier_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_med, get_mad, has_artefact\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'outlier_detection'"
     ]
    }
   ],
   "source": [
    "from outlier_detection import get_med, get_mad, has_artefact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e82cbb-5063-4422-b75f-fa3a664bc956",
   "metadata": {},
   "source": [
    "### Inspect a section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7f130-9943-43f6-90b4-fad1eb9c1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select z\n",
    "z = 33\n",
    "# Collect filepaths to raw data for given section\n",
    "d = df_fps.loc[z].to_dict()\n",
    "dir_data_raw = Path(\"/long_term_storage/asm_storage/asm_service/\") / d['Date'] / d['Project'] / d['ROA']\n",
    "fps_data_raw = sorted(dir_data_raw.glob('*_0.tiff'))\n",
    "fps_data_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd6d3a-65ee-48ef-9703-9a2febe6899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median and median absolute deviation\n",
    "pct = 1\n",
    "med = get_med(fps_data_raw, pct=pct)\n",
    "mad = get_mad(fps_data_raw, med=med, pct=pct)\n",
    "\n",
    "# Create figure\n",
    "nrows, ncols, _ = [int(i) + 1 for i in fps_data_raw[-1].stem.split('_')]\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows,\n",
    "                         figsize=(4*ncols, 4*nrows))\n",
    "\n",
    "# Loop through raw tiffs, keeping track of artefact-less fields\n",
    "fps_clean = []\n",
    "for fp in tqdm(fps_data_raw):\n",
    "\n",
    "    # Determine row, col\n",
    "    row, col, _ = [int(i) for i in fp.stem.split('_')]\n",
    "    # Read tiff and extract lowest resolution page from pyramid\n",
    "    tiff = TiffFile(fp.as_posix())\n",
    "    image = tiff.pages[-1].asarray()\n",
    "    dy, dx = image.shape\n",
    "\n",
    "    # Detect artefacts\n",
    "    corrupted = has_artefact(image, med=med, mad=mad, pct=pct, a=3)\n",
    "\n",
    "    # Colorize\n",
    "    tint_green = np.array([0, 1, 0, 0.1])\n",
    "    tint_red = np.array([1, 0, 0, 0.1])\n",
    "    if corrupted:\n",
    "        mask = np.ones((dy, dx, 4)) * tint_red\n",
    "    else:\n",
    "        mask = np.ones((dy, dx, 4)) * tint_green\n",
    "        fps_clean.append(fp)\n",
    "\n",
    "    # Plot image + mask\n",
    "    axes[row, col].imshow(image, cmap='Greys_r',\n",
    "                          vmin=52800, vmax=60200)\n",
    "    axes[row, col].imshow(mask)\n",
    "\n",
    "    # Give label\n",
    "    title = f\"{row:03d} x {col:03d}\"\n",
    "    axes[row, col].text(0.5, 0.95, title, ha='center', va='top',\n",
    "                        transform=axes[row, col].transAxes,\n",
    "                        fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    # Remove axis ticks\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "# Aesthetics\n",
    "plt.subplots_adjust(hspace=0.02, wspace=-0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab537e05-2a95-4424-81f3-6846a5201b6f",
   "metadata": {},
   "source": [
    "### Re-post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590ddd8-f770-41ea-8c52-4b27f00f2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from skimage.transform import pyramid_gaussian\n",
    "\n",
    "def save_pyramidal_tiff(filepath, image, metadata, n_layers=5, options=None):\n",
    "    \"\"\"Save image as multi-page, pyramidal tiff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : `pathlib.Path`\n",
    "        Filepath to save tiff\n",
    "    image : array-like\n",
    "        Input image, becomes the base-level of the pyramid\n",
    "    metadata : dict\n",
    "        Tiff metadata\n",
    "    n_layers : int (optional)\n",
    "        Number of layers\n",
    "    options : dict (optional)\n",
    "        Extra optional metadata\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#saving-tiff-images\n",
    "    \"\"\"\n",
    "    # Generate image pyramid\n",
    "    pyramid = pyramid_gaussian(image,\n",
    "                               downscale=2,\n",
    "                               order=3,\n",
    "                               max_layer=n_layers,\n",
    "                               preserve_range=True)\n",
    "\n",
    "    # Extract layers from pyramid and force uint16\n",
    "    layers = [Image.fromarray(layer.astype(np.uint16)) for layer in pyramid]\n",
    "\n",
    "    # Handle metadata\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "\n",
    "    # Use funky PIL thing because it works\n",
    "    im = layers[0]\n",
    "    im.save(filepath.as_posix(), append_images=layers[1:],\n",
    "            tiffinfo=metadata, save_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f15c7-16f4-4339-acf4-7e557c7ec923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess(dir_data_raw, fps_clean):\n",
    "    \"\"\"Reapply post-processing corrections\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_data_raw : `pathlib.Path`\n",
    "        Filepath to directory containing the raw fields to reprocess\n",
    "    fps_clean : list-like\n",
    "        List of filepaths of artefact-free fields\n",
    "    \"\"\"\n",
    "    # Borrow some technolution naming conventions\n",
    "    restore_mean_level = 32768\n",
    "    sum_of_files = 0.0  # set to float to avoid integer overflow\n",
    "    # Set target output directory\n",
    "    dir_data_corrected = dir_data_raw / 'corrected'\n",
    "\n",
    "    # Estimate background by averaging over clean images\n",
    "    for fp in tqdm(fps_clean, desc=\"Estimating background\"):\n",
    "        # Load tiff\n",
    "        tiff = TiffFile(fp.as_posix())\n",
    "        image = tiff.pages[0].asarray()\n",
    "        # Sum all the clean images together\n",
    "        sum_of_files += image\n",
    "\n",
    "    # Make the sum a mean\n",
    "    background = sum_of_files / len(fps_clean)\n",
    "\n",
    "    # Collect filepaths to raw fields\n",
    "    fps_raw = sorted(dir_data_raw.glob('*_0.tiff'))\n",
    "    # Loop through raw fields\n",
    "    for fp in tqdm(fps_raw, desc=\"Background subtraction / re-exporting\"):\n",
    "        # Load tiff\n",
    "        tiff = TiffFile(fp.as_posix())\n",
    "        image = tiff.pages[0].asarray()\n",
    "        # Subtract background from each raw field\n",
    "        # and restore to 16bit mean level\n",
    "        corrected = (image - background + restore_mean_level).astype(np.uint16)\n",
    "\n",
    "        # Save corrected field as pyramidal tiff\n",
    "        fp_tgt = dir_data_corrected / fp.name\n",
    "        save_pyramidal_tiff(fp_tgt, corrected, None)\n",
    "    # Save background\n",
    "    save_pyramidal_tiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc7627-e189-43c4-83ce-c86860af0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprocess\n",
    "reprocess(dir_data_raw, fps_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09facde-4a8f-498a-87dc-1118af6339ca",
   "metadata": {},
   "source": [
    "### Inspect re-post-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74f789-1cb5-4f62-897f-1d2cefecd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect reprocessed filepaths\n",
    "fps_data_reprocessed = sorted((dir_data_raw / 'corrected').glob('*_0.tiff'))\n",
    "\n",
    "# Create figure\n",
    "nrows, ncols, _ = [int(i) + 1 for i in fps_data_raw[-1].stem.split('_')]\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows,\n",
    "                         figsize=(4*ncols, 4*nrows))\n",
    "\n",
    "# Loop through raw tiffs, keeping track of artefact-less fields\n",
    "for fp in tqdm(fps_data_reprocessed):\n",
    "\n",
    "    # Determine row, col\n",
    "    row, col, _ = [int(i) for i in fp.stem.split('_')]\n",
    "    # Read tiff and extract lowest resolution page from pyramid\n",
    "    tiff = TiffFile(fp.as_posix())\n",
    "    image = tiff.pages[-1].asarray()\n",
    "    dy, dx = image.shape\n",
    "\n",
    "    # Plot image + mask\n",
    "    axes[row, col].imshow(image, cmap='Greys_r',\n",
    "                          vmin=28600, vmax=35900)\n",
    "\n",
    "    # Give label\n",
    "    title = f\"{row:03d} x {col:03d}\"\n",
    "    axes[row, col].text(0.5, 0.95, title, ha='center', va='top',\n",
    "                        transform=axes[row, col].transAxes,\n",
    "                        fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    # Remove axis ticks\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "# Aesthetics\n",
    "plt.subplots_adjust(hspace=0.02, wspace=-0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edf4b7-2c0b-4566-9969-05a8030cde1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
